{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Causal Inference in Non-Randomized Experiments\n",
    "\n",
    "**Author**: Leo Guelman\n",
    "\n",
    "* [1. Problem Statment](#problem1)\n",
    " * [1.1 The National Study of Learning Mindsets](#mindsets11)\n",
    " * [1.2 Data Description](#data12)\n",
    " * [1.2 The Questions](#questions13)\n",
    "* [2. Analysis](#analysis2) \n",
    " * [2.1 Imports](#imports21)\n",
    "\n",
    "* [References](#ref)\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem Statment <a class=\"anchor\" id=\"problem1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 The National Study of Learning Mindsets <a class=\"anchor\" id=\"mindsets11\"></a>\n",
    "\n",
    "We look at the causal inference challenge presented by the *National Study of Learning Mindsets* (Yeager et al., 2019) from a Bayesian perspective. \n",
    "\n",
    "The NSLM is a randomized experiment designed to assess the effectiveness of an intervention to improve academic outcomes of students with a *growth mindset*. The *growth mindset* is a belief that people can develop intelligence, as opposed to the *fixed mindset* view which sees intelligence as an innate trait that is fixed at birth.\n",
    "\n",
    "The original study consisted in a randomized experiment composed of students from 76 schools drawn from the national probability sample of U.S. public schools. In addition, to assessing the average treatment effect (ATE), the study was designed to estimate the degree of heterogeneity in treatment effect across both students and schools. \n",
    "\n",
    "A synthetic dataset was generated to mimic the original data, but with the goal of creating an observational study that includes confounding effects not present in the original randomized experiment. Besides this difference, the synthetic data resembles the real NSLM data in terms of covariate distribution, data structures, and effect sizes. \n",
    "\n",
    "During the 2018 Atlantic Causal Inference Conference, eight groups of participans were invited to analyze the synthetic data to assess the questions of average treatment effect and treatment effect variation in non-randomized experimental settings. Participants employed a diverse set of methods, ranging from matching and flexible outcome modeling to semiparametric estimation and ensemble approaches. In this study, we employ an alternative approach founded in Bayesian inference principles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Description <a class=\"anchor\" id=\"data12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis is based on the sythetic dataset of $n=10,391$ children from a sample of $J=76$ schools. For each children $i=\\{1, \\ldots, n\\}$, we observe a binary treatment indicator $Z_i$, a real-valued outcome $Y_i$, as well as 10 categorical or real-valued covariates as outlined in the table below. For a full description of the data generating process refer to Carvalho et al., 2019.\n",
    "\n",
    "\n",
    "| Covariate | Description |\n",
    "| :---        |    :----   | \n",
    "| S3 | Student’s self-reported expectations for success in the future, a proxy for prior achievement, measured prior to random assignment|\n",
    "| C1 | Categorical variable for student race/ethnicity |\n",
    "|C2 | Categorical variable for student identified gender\n",
    "|C3 | Categorical variable for student first-generation status, i.e. first in family to go to college\n",
    "|XC | School-level categorical variable for urbanicity of the school, i.e. rural, suburban, etc.\n",
    "| X1 | School-level mean of students’ fixed mindsets, reported prior to random assignment\n",
    "| X2|  School achievement level, as measured by test scores and college preparation for the previous 4 cohorts of students\n",
    "|X3  | School racial/ethnic minority composition, i.e., percentage of student body that is Black, Latino, or Native American\n",
    "| X4 | School poverty concentration, i.e., percentage of students who are from families whose incomes fall below the federal poverty line\n",
    "| X5 | School size, i.e., total number of students in all four grade levels in the school\n",
    "| Y | Post-treatment outcome, a continuous measure of achievement\n",
    "|Z | Treatment, i.e., receipt of the intervention\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 The Questions <a class=\"anchor\" id=\"questions13\"></a>\n",
    "\n",
    "The two questions we are aiming to address as part of this study are the following:\n",
    "\n",
    "1. Was the mindset intervention effective in improving student achievement?\n",
    "2. Was the effect of the intervention moderated by school level achievement (X2) or pre-existing mindset norms (X1)? In particular there are two competing hypotheses about how X2 moderates the effect of the intervention: Either it is largest in middle-achieving schools (a \"Goldilocks effect\") or is decreasing in school-level achievement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Analysis <a class=\"anchor\" id=\"analysis2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Imports <a class=\"anchor\" id=\"imports21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/lguelman/Library/Mobile Documents/com~apple~CloudDocs/LG_Files/Development/BCI/python')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "parameters = {'figure.figsize': (8, 4),\n",
    "              'font.size': 8, \n",
    "              'axes.labelsize': 12}\n",
    "plt.rcParams.update(parameters)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import pystan\n",
    "import multiprocessing\n",
    "import stan_utility\n",
    "import arviz as az\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from acic_utils import preprocess_p_scores, stan_model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Get Data  <a class=\"anchor\" id=\"data22\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/synthetic_data.csv\")\n",
    "df\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Assessing Balance of Covariates\n",
    "\n",
    "Covariate balance is the degree to which the distribution of covariates is similar across levels of the treatment. Here we assess the extent to which the treatment assignment was uniformly randomized accross observational units, or there are some selection effects. To that end, we use *Prognostic scores* (Hansen 2008).\n",
    "\n",
    "The prognostic score is defined as the predicted outcome under the control condition, reflecting the baseline \"risk\". It is estimated by fitting a model of the outcome in the control group, and then using that model to to obtain predictions of the outcome under the control condition for all individuals. The standardize difference in the mean prognostic scores between treatment and control groups is the used as a meansure of covariate balance. \n",
    "\n",
    "Here we simply use a Bayesian linear regression model to get a posterior distribution of the standardize difference in the mean prognostic scores between treatment and control groups.\n",
    "\n",
    "We first pre-process the data (encode categorical features and scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, z, y = preprocess_p_scores(df)\n",
    "\n",
    "print(\"Features dimension:\", X.shape)\n",
    "print(\"Treatment dimension:\", z.shape)\n",
    "print(\"Response dimension:\", y.shape)\n",
    "print(\"Number of treated / control units:\", sum(z), \"/\", X.shape[0]-sum(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the model in stan. We store the stan code spearatetly in `stan_linear_reg.stan` within the `stan` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = X[z==0,:].shape # Fit model using control units only\n",
    "\n",
    "stan_data_dict = {'N': n,\n",
    "                  'K': p,\n",
    "                  'x': X[z==0,:],\n",
    "                  'y': y[z==0],\n",
    "                  'N_new': X.shape[0],\n",
    "                  'x_new': X\n",
    "                  }\n",
    "\n",
    "sm = pystan.StanModel('../stan/stan_linear_reg.stan') \n",
    "multiprocessing.set_start_method(\"fork\", force=True)\n",
    "fit = sm.sampling(data=stan_data_dict, iter=1000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_summary = stan_model_summary(fit)\n",
    "fit_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the analysis below, notice that students with highest potential outcomes under control are more likely to receive treatment. Thus, we proceed the analysis as an observational study instead on a randomized one. \n",
    "\n",
    "**Add issues based on Bayesian Tree paper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract prognostic scores\n",
    "samples = fit.extract(permuted=True)\n",
    "prog_scores = samples['prog_scores'].T\n",
    "\n",
    "# Compute mean and standardize mean differences in scores\n",
    "mcmc_samples = prog_scores.shape[1]\n",
    "prog_scores_std_diff = np.zeros(mcmc_samples)\n",
    "\n",
    "for s in range(mcmc_samples):\n",
    "    prog_scores_diff[s] = np.mean(prog_scores[z==1,s]) - np.mean(prog_scores[z==0,s])\n",
    "    prog_scores_std_diff[s] = prog_scores_diff[s] / np.std(prog_scores[:,s])\n",
    "  \n",
    "                               \n",
    "plt.hist(prog_scores_std_diff, bins = 30)\n",
    "plt.title(\"Standardized mean difference in Prognostic scores\", fontsize=12)\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_scores_df = pd.DataFrame({'prog_score_mean': np.mean(prog_scores, axis =1),'z':z})\n",
    "prog_scores_df['prog_score_mean_quantile']= pd.qcut(prog_scores_df['prog_score_mean'], \n",
    "                                                    q = 5, labels = False)+1\n",
    "prog_scores_df.groupby(['prog_score_mean_quantile'])['z'].mean().plot(xticks=list(range(1,6)), \n",
    "                                                                     xlabel='Mean Prognostic Score (Quantile)',\n",
    "                                                                     ylabel='Proportion treated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References <a class=\"anchor\" id=\"ref\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeager, D.S., Hanselman, P., Walton, G.M. et al. A national experiment reveals where a growth mindset improves achievement. Nature 573, 364–369 (2019). https://doi.org/10.1038/s41586-019-1466-y\n",
    "\n",
    "Carvalho, C., Feller, A., Murray, J., Woody, S., and Yeager, D. Assessing Treatment Effect Variation in Observational Studies: Results from a Data Challenge, (2019). https://arxiv.org/abs/1907.07592\n",
    "\n",
    "Hansen, Ben B. The Prognostic Analogue of the Propensity Score. Biometrika 95 (2), 481–88, (2008). https://doi.org/10.1093/biomet/asn004."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
