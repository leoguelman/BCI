{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Causal Inference in Non-Randomized Experiments\n",
    "\n",
    "**Author**: Leo Guelman\n",
    "\n",
    "* [1. Problem Statment](#problem1)\n",
    "    * [1.1 The National Study of Learning Mindsets](#mindsets11)\n",
    "    * [1.2 Data Description](#data12)\n",
    "    * [1.2 The Questions](#questions13)\n",
    "* [2. Analysis](#analysis2) \n",
    "    * [2.1 Imports](#imports21)\n",
    "    * [2.2 Data](#data22)\n",
    "    * [2.3 Assessing Balance of Covariates](#balance23)\n",
    "    * [2.4 Propensity score](#propscore24)\n",
    "    * [2.5 Model-based Inference](#mbinference25)\n",
    "        * [2.5.1 MCMC Diagnostics](#mcmcdiagn251)\n",
    "        * [2.5.2 Effectivness of Intervention](#effint252)\n",
    "        * [2.5.3 Treatment effect variation across](#hetero253)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Problem Statment <a class=\"anchor\" id=\"problem1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 The National Study of Learning Mindsets <a class=\"anchor\" id=\"mindsets11\"></a>\n",
    "\n",
    "We look at the causal inference challenge presented by the *National Study of Learning Mindsets* (Yeager et al., 2019) from a Bayesian perspective. \n",
    "\n",
    "The NSLM is a randomized experiment designed to assess the effectiveness of an intervention to improve academic outcomes of students with a *growth mindset*. The *growth mindset* is a belief that people can develop intelligence, as opposed to the *fixed mindset* view which sees intelligence as an innate trait that is fixed at birth.\n",
    "\n",
    "The original study consisted in a randomized experiment composed of students from 76 schools drawn from the national probability sample of U.S. public schools. In addition, to assessing the average treatment effect (ATE), the study was designed to estimate the degree of heterogeneity in treatment effect across both students and schools. \n",
    "\n",
    "A synthetic dataset was generated to mimic the original data, but with the goal of creating an observational study that includes confounding effects not present in the original randomized experiment. Besides this difference, the synthetic data resembles the real NSLM data in terms of covariate distribution, data structures, and effect sizes. \n",
    "\n",
    "During the 2018 Atlantic Causal Inference Conference (ACIC 2018), eight groups of participans were invited to analyze the synthetic data to assess the questions of average treatment effect and treatment effect variation in non-randomized experimental settings. Participants employed a diverse set of methods, ranging from matching and flexible outcome modeling to semiparametric estimation and ensemble approaches. In this study, we employ an alternative approach founded in Bayesian inference principles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Description <a class=\"anchor\" id=\"data12\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis is based on the sythetic dataset of $n=10,391$ children from a sample of $J=76$ schools. For each children $i=\\{1, \\ldots, n\\}$, we observe a binary treatment indicator $Z_i$, a real-valued outcome $Y_i$, as well as 10 categorical or real-valued covariates as outlined in the table below. For a full description of the data generating process refer to Carvalho et al., 2019.\n",
    "\n",
    "\n",
    "| Covariate | Description |\n",
    "| :---        |    :----   | \n",
    "| S3 | Student’s self-reported expectations for success in the future, a proxy for prior achievement, measured prior to random assignment|\n",
    "| C1 | Categorical variable for student race/ethnicity |\n",
    "|C2 | Categorical variable for student identified gender\n",
    "|C3 | Categorical variable for student first-generation status, i.e. first in family to go to college\n",
    "|XC | School-level categorical variable for urbanicity of the school, i.e. rural, suburban, etc.\n",
    "| X1 | School-level mean of students’ fixed mindsets, reported prior to random assignment\n",
    "| X2|  School achievement level, as measured by test scores and college preparation for the previous 4 cohorts of students\n",
    "|X3  | School racial/ethnic minority composition, i.e., percentage of student body that is Black, Latino, or Native American\n",
    "| X4 | School poverty concentration, i.e., percentage of students who are from families whose incomes fall below the federal poverty line\n",
    "| X5 | School size, i.e., total number of students in all four grade levels in the school\n",
    "| Y | Post-treatment outcome, a continuous measure of achievement\n",
    "|Z | Treatment, i.e., receipt of the intervention\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 The Questions <a class=\"anchor\" id=\"questions13\"></a>\n",
    "\n",
    "The two questions we are aiming to address as part of this study are the following:\n",
    "\n",
    "1. Was the mindset intervention effective in improving student achievement?\n",
    "2. Was the effect of the intervention moderated by school level achievement (`X2`) or pre-existing mindset norms (`X1`)? In particular there are two competing hypotheses about how `X2` moderates the effect of the intervention: Either it is largest in middle-achieving schools (a \"Goldilocks effect\") or is decreasing in school-level achievement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Analysis <a class=\"anchor\" id=\"analysis2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Imports <a class=\"anchor\" id=\"imports21\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/Users/lguelman/Library/Mobile Documents/com~apple~CloudDocs/LG_Files/Development/BCI/python')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "parameters = {'figure.figsize': (8, 4),\n",
    "              'font.size': 8, \n",
    "              'axes.labelsize': 12}\n",
    "plt.rcParams.update(parameters)\n",
    "plt.style.use('fivethirtyeight')\n",
    "from IPython.display import Image\n",
    "\n",
    "import pystan\n",
    "import multiprocessing\n",
    "import stan_utility\n",
    "import arviz as az\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from acic_utils import pre_process_data, stan_model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data  <a class=\"anchor\" id=\"data22\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/synthetic_data.csv\")\n",
    "df\n",
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Assessing Balance of Covariates <a class=\"anchor\" id=\"balance23\"></a>\n",
    "\n",
    "Covariate balance is the degree to which the distribution of covariates is similar across levels of the treatment. Here we assess the extent to which the treatment assignment was uniformly randomized across observational units, or there are some selection effects. To that end, we use *Prognostic scores* (Hansen 2008). The prognostic score is defined as the predicted outcome under the control condition, reflecting the baseline \"risk\", i.e., $E(Y|X, Z=0)$. It is estimated by fitting a model of the outcome in the control group, and then using that model to obtain predictions of the outcome under the control condition for all individuals. The standardize difference in the mean prognostic scores between treatment and control groups is used as a measure of covariate balance. \n",
    "\n",
    "Here we fit a Bayesian linear regression model to get a posterior distribution of the standardize difference in the mean prognostic scores between treatment and control groups.\n",
    "\n",
    "We first pre-process the data (encode categorical features and scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, z, y, *_ = pre_process_data(df, standardize_x=False, interactions=False, \n",
    "                               p_score=None, drop_first=False)\n",
    "\n",
    "print(\"Features dimension:\", X.shape)\n",
    "print(\"Treatment dimension:\", z.shape)\n",
    "print(\"Response dimension:\", y.shape)\n",
    "print(\"Number of treated / control units:\", sum(z), \"/\", X.shape[0]-sum(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit the model in [stan](https://mc-stan.org/). We place the stan code separately in `stan_linear_reg.stan`, stored in the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = X[z==0,:].shape # Fit model using control units only\n",
    "\n",
    "stan_data_dict = {'N': n,\n",
    "                  'K': p,\n",
    "                  'x': X[z==0,:],\n",
    "                  'y': y[z==0],\n",
    "                  'N_new': X.shape[0],\n",
    "                  'x_new': X\n",
    "                  }\n",
    "\n",
    "sm = pystan.StanModel('../stan/stan_linear_reg.stan') \n",
    "multiprocessing.set_start_method(\"fork\", force=True)\n",
    "fit = sm.sampling(data=stan_data_dict, iter=1000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_summary = stan_model_summary(fit)\n",
    "fit_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standardize mean difference in Prognostic scores is positive meaning that students with highest potential outcomes under control are more likely to receive treatment. This can also be appreciated by plotting the proportion of individuals assigned to treatment for by quantile of the prognostic score (each quantile comprises about 1/5 of the observations). In this case, we say that the treatment assignment mechanisms is *counfounded* with the potential outcomes (i.e., the value of the outcome for each subject under each treatment, only one of which is observed).\n",
    "\n",
    "In this context, a simple comparison of treated versus control individuals would produce bias estimates of treatment effects (both average and conditional effects). We thus proceed the analysis as an observational study instead on a randomized one. Specifically, to address this problem we directly incorporate an estimate of the *propensity score* in the specification of the outcome model, implicitly inducing a covariate dependent prior on the regression function (see Hahn 2020).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract prognostic scores\n",
    "samples = fit.extract(permuted=True)\n",
    "prog_scores = samples['prog_scores'].T\n",
    "\n",
    "# Compute mean and standardize mean differences in scores\n",
    "mcmc_samples = prog_scores.shape[1]\n",
    "prog_scores_diff = np.zeros(mcmc_samples)\n",
    "prog_scores_std_diff = np.zeros(mcmc_samples)\n",
    "\n",
    "for s in range(mcmc_samples):\n",
    "    prog_scores_diff[s] = np.mean(prog_scores[z==1,s]) - np.mean(prog_scores[z==0,s])\n",
    "    prog_scores_std_diff[s] = prog_scores_diff[s] / np.std(prog_scores[:,s])\n",
    "  \n",
    "                               \n",
    "plt.hist(prog_scores_std_diff, bins = 30)\n",
    "plt.title(\"Standardized mean difference in Prognostic scores\", fontsize=12)\n",
    "plt.show()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute proportion treated by mean prognostic score quantile\n",
    "prog_scores_df = pd.DataFrame({'prog_score_mean': np.mean(prog_scores, axis =1),'z':z})\n",
    "prog_scores_df['prog_score_mean_quantile']= pd.qcut(prog_scores_df['prog_score_mean'], \n",
    "                                                    q = 5, labels = False)+1\n",
    "prog_scores_df.groupby(['prog_score_mean_quantile'])['z'].mean().plot(xticks=list(range(1,6)), \n",
    "                                                                     xlabel='Mean Prognostic Score (Quantile)',\n",
    "                                                                     ylabel='Proportion Treated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Propensity Score <a class=\"anchor\" id=\"propscore24\"></a>\n",
    "\n",
    "The propensity score is the probability of treatment assignment conditional on observed baseline covariates, i.e., $E(Z|X)$. Here we fit the propensity score using a flexible non-linear specification based on a Gradient Boosting method. Parameter tuning is done via cross-validated random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "n_folds = 3\n",
    "param_n_picks = 30\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.01, n_estimators=500, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle = True, random_state = 42)\n",
    "\n",
    "xgb_fits = RandomizedSearchCV(xgb, param_distributions=param_grid,\n",
    "                              n_iter=param_n_picks, scoring='roc_auc', n_jobs=-1, \n",
    "                              cv=skf.split(X,z), verbose=3, random_state=42)\n",
    "\n",
    "xgb_fits.fit(X, z)\n",
    "\n",
    "print('\\n Best estimator:')\n",
    "print(xgb_fits.best_estimator_)\n",
    "print('\\n Best AUC score:')\n",
    "print(xgb_fits.best_score_)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(xgb_fits.best_params_)\n",
    "\n",
    "# We now fit the best estimator to all train data \n",
    "best_fit = xgb_fits.best_estimator_.fit(X, z)\n",
    "pscore = best_fit.predict_proba(X)[:,1]\n",
    "log_odds_pscore = np.log(pscore /(1-pscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_score_df = pd.DataFrame({'log_odds_pscore': log_odds_pscore, 'Z':z})\n",
    "sns.displot(prop_score_df, x=\"log_odds_pscore\", \n",
    "            hue=\"Z\",  stat=\"density\", common_norm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Model-based Inference <a class=\"anchor\" id=\"mbinference25\"></a>\n",
    "\n",
    "\n",
    "We implement the Bayesian inference framework for causal effects introduced by Rubin (1978). In this framework, each observational unit $i=\\{1,\\ldots, N\\}$ is seen as having a potential outcome for each level of treatment. In the binary treatment case with $Z \\in [0,1]$, $Y_i(1)$ and $Y_i(0)$ represent the potential outcomes of unit $i$ under $Z=1$ and \n",
    "$Z=0$, respectively. Causal inference is considered a missing data problem since both potential outcomes are never jointly observed. Specifically, observed and missing outcomes can be expressed in terms of the potential outcomes as follows:\n",
    "\n",
    "\\begin{align*} \n",
    "Y_i^{\\text{obs}} &=  Y_i(1)Z_i + Y_i(0)(1-Z_i) \\\\ \n",
    "Y_i^{\\text{mis}} &=  Y_i(1)(1-Z_i) + Y_i(0)Z_i\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "From a Bayesian perspective, $Y_i^{\\text{mis}}$ is considered a latent variable, similar to any other latent variable in the model (I'm trying to avoid the term \"parameters\" here, which is more common in the frequentist language). The missing potential outcomes can be imputed by estimating their posterior predictive distribution given the observed data. That is,\n",
    "\n",
    "$$\n",
    "\\text{Pr}(Y^{\\text{mis}}| Y^{\\text{obs}},Z, X).\n",
    "$$\n",
    "\n",
    "Estimating the conditional distribution of $Y^{\\text{mis}}$ given $(Y^{\\text{obs}},Z, X)$, requires building a model of the joint distribution of potential outcomes $(Y(0), Y(1))$. We assume that the true underlying model for the potential outcomes follows a bivariate Gaussian, \n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "Y_i(0) \\\\\n",
    "Y_i(1) \n",
    "\\end{pmatrix} \\bigg\\lvert~X_i, \\theta \\sim N \\left(\\begin{pmatrix}\n",
    "\\alpha + X_i\\beta_c \\\\\n",
    "\\alpha + X_i\\beta_t + \\tau\n",
    "\\end{pmatrix},\\begin{pmatrix}\n",
    "\\sigma_c^{2} & \\rho\\sigma_c\\sigma_t \\\\\n",
    "\\rho\\sigma_c\\sigma_t & \\sigma_t^{2}\n",
    "\\end{pmatrix}\\right),\n",
    "$$\n",
    "\n",
    "where $\\theta=(\\alpha, \\beta_c, \\beta_t, \\tau, \\sigma_c^2, \\sigma_t^2, \\rho)$.\n",
    "\n",
    "From this model, we can derive the conditional distribution of each potential outcome as\n",
    "\n",
    "\n",
    "\\begin{align*} \n",
    "\\text{Pr}(Y_i(1) | Y_i(0), \\theta, Z_i=0) &\\sim N \\Big(\\mu_t+ \\rho \\frac{\\sigma_t}{\\sigma_c} (Y_i(0)-\\mu_c), \\sigma^2_t(1-\\rho^2)\\Big),\\\\\n",
    "\\text{Pr}(Y_i(0) | Y_i(1), \\theta, Z_i=1) &\\sim N \\Big(\\mu_c+ \\rho \\frac{\\sigma_c}{\\sigma_t} (Y_i(1)-\\mu_t), \\sigma^2_c(1-\\rho^2)\\Big), \n",
    "\\end{align*}\n",
    "\n",
    "where $\\mu_c = \\alpha + X\\beta_c$, and $\\mu_t = \\alpha + X\\beta_t + \\tau$.\n",
    "\n",
    "From the distribution of potential outcomes, we can infer the distribution of any estimand of interest of the form $\\tau = \\tau(Y(0),Y(1), X, Z)$. For instance, the average treatment effect (ATE) can be obtained by simply computing $\\frac{1}{N}\\sum_{i=1}^N(Y_i(1)-Y_i(0))$. This is also known as the \"finite sample\" ATE. If instead, we view the observations as a sample from an infinite super-population, then the super-population ATE is given from the posterior distribution of $\\tau$.\n",
    "\n",
    "A few observations from the model above:\n",
    "\n",
    "* Since $Y_i(0)$ and $Y_i(1)$ are never jointly observed, the correlation between outcomes, $\\rho$, cannot be estimated empirically. It must be based on subject-matter knowledge. Sometimes we may choose to be \"conservative\" about this dependence and therefore assume the worst case. In terms of the posterior variance, the worst case is often the situation of perfect correlation between the two potential outcomes.\n",
    "\n",
    "* There are two sources of uncertainty in the predictive distribution of the missing potential outcomes: the first is the uncertainty in the estimated latent variables (a.k.a., *epistemic uncertainty*), and the second in the uncertainty in the data as expressed by the Gaussian random sampling mechanism (a.k.a., *aleatoric uncertainty*).\n",
    "\n",
    "* We allow for heterogeneous treatment effects - i.e., we define two different vectors $\\beta_c$ and  $\\beta_t$, for control and treated units, respectively. In the **Stan** model below (see `stan_mbi.stan`), this heterogeneity is expressed by including interaction terms between each covariate and the treatment. The posterior estimates on the interaction effects represent the incremental effect of treatment $\\beta_t - \\beta_c$.\n",
    "\n",
    "* The propensity score is considered as an additional covariate in $X$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,z, y, a_effects, m_effects, i_effects = pre_process_data(df, standardize_x=False, interactions=True, \n",
    "                                                            p_score=pscore, drop_first=False)\n",
    "\n",
    "# Get indexes of main and interaction effects\n",
    "idx_m_effects = [a_effects.index(i) for i in m_effects]\n",
    "idx_i_effects = [a_effects.index(i) for i in i_effects]\n",
    "\n",
    "print(X.shape)\n",
    "print(len(idx_m_effects))\n",
    "print(len(idx_i_effects))\n",
    "print(X[:,idx_m_effects].shape)\n",
    "print(X[:,idx_i_effects].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_data_mbi = {'N': X.shape[0], \n",
    "                 'N_main_cov':len(idx_m_effects),\n",
    "                 'N_inter_cov':len(idx_i_effects),\n",
    "                 'y': y,\n",
    "                 'z': z,\n",
    "                 'x': X[:,idx_m_effects],\n",
    "                 'xz_inter': X[:,idx_i_effects],\n",
    "                 'rho':0.0}\n",
    "\n",
    "sm = pystan.StanModel('../stan/stan_mbi.stan') \n",
    "multiprocessing.set_start_method(\"fork\", force=True)\n",
    "fit_mbi = sm.sampling(data=stan_data_mbi, iter=1000, chains=4, seed=194838)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 MCMC Diagnostics <a class=\"anchor\" id=\"mcmcdiagn251\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stan_fit = stan_model_summary(fit_mbi)\n",
    "summary_stan_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_hat = summary_stan_fit['Rhat']\n",
    "r_hat.plot.hist(title=\"Rhat\")\n",
    "plt.axvline(1.1, color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stan_fit['n_eff'].plot.hist(title=\"n_eff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_utility.utils.check_treedepth(fit_mbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_utility.utils.check_energy(fit_mbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_utility.utils.check_div(fit_mbi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2  Effectiveness of Intervention<a class=\"anchor\" id=\"effint252\"></a>\n",
    "\n",
    "Here we address the first study question, which we recall is \"*Was the mindset intervention effective in improving student achievement?*\" This relates to the *Average Treatment Effect (ATE)*. The estimated (finite-sample) **ATE is 0.24 with a 95% uncertainty interval between 0.22 and 0.26. The true value based on the simulation is also 0.24**, so we are right on spot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taus = summary_stan_fit.loc[['tau_fs']]\n",
    "taus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison purposes, we show below the submitted estimates for average treatment effects and corresponding 95% uncertainty intervals from eight ACIC 2018 challenge participants (Carvalho 2019). Our estimate is closer to the true value relative to all submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = \"../img/acic_ate.png\", width = 300, height = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3  Treatment effect variation across `X1` and `X2` <a class=\"anchor\" id=\"hetero253\"></a>\n",
    "\n",
    "The second question of the study is directed to assess the treatment effect variation across the two pre-specified moderators, `X1` (pre-existing mindset norms) and `X2` (school level achievement).\n",
    "\n",
    "We look at the posterior estimates of interaction effects `Z x X1` and `Z x X2`. This effect represent the incremental effect of treatment $\\beta_t - \\beta_c$ from `X1` and `X2`, respectively. The results depicted below indicate that a higher baseline mindset beliefs tends to be associated with lower treatment effect on average. In contrast, there appears to be no support for treatment effect variation across school achievement levels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = fit_mbi.extract(permuted=True)\n",
    "\n",
    "Z_X1_samples = samples['beta_inter'][:,i_effects.index('Z_X1')]\n",
    "Z_X2_samples = samples['beta_inter'][:,i_effects.index('Z_X2')]\n",
    "\n",
    "g1 = sns.displot(Z_X1_samples,\n",
    "    kind=\"kde\")\n",
    "g1.set_axis_labels(\"Interaction effect (Z x X1) posterior samples\", \n",
    "                  \"Density\", fontsize=10)\n",
    "\n",
    "g2 = sns.displot(Z_X2_samples,\n",
    "    kind=\"kde\")\n",
    "g2.set_axis_labels(\"Interaction effect (Z x X2) posterior samples\", \n",
    "                  \"Density\", fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References <a class=\"anchor\" id=\"ref\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carvalho, C., Feller, A., Murray, J., Woody, S., and Yeager, D. Assessing Treatment Effect Variation in Observational Studies: Results from a Data Challenge, (2019). https://arxiv.org/abs/1907.07592\n",
    "\n",
    "Donald B. Rubin. Bayesian Inference for Causal Effects: The Role of Randomization. Ann. Statist. 6 (1) 34 - 58 (1978). https://doi.org/10.1214/aos/1176344064\n",
    "\n",
    "Hahn, P.R., Murray, J.S., Carvalho, C.M. Bayesian Regression Tree Models for Causal Inference: Regularization, Confounding, and Heterogeneous Effects (with Discussion). Bayesian Analysis. 15 (3) 965 - 1056 (2020). https://doi.org/10.1214/19-BA1195\n",
    "\n",
    "Hansen, Ben B. The Prognostic Analogue of the Propensity Score. Biometrika 95 (2), 481–88, (2008). https://doi.org/10.1093/biomet/asn004.\n",
    "\n",
    "Yeager, D.S., Hanselman, P., Walton, G.M. et al. A national experiment reveals where a growth mindset improves achievement. Nature 573, 364–369 (2019). https://doi.org/10.1038/s41586-019-1466-y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
